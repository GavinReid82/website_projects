{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e571cafd-1b17-44c4-8b1c-df1833faf826",
   "metadata": {},
   "source": [
    "# Project Overview: Logistic Regression for Binary Classification\n",
    "\n",
    "In this project, I aim to demonstrate the use of **logistic regression** to perform a **binary classification task**. Logistic regression is an extension of linear regression that uses a sigmoid function to map predictions into a probability range between 0 and 1. This project leverages the `scikit-learn` (or `sklearn`) library to fit a logistic regression model to a dataset and make predictions based on input features.\n",
    "\n",
    "## Key Objectives\n",
    "- **Understand logistic regression**: Logistic regression models the relationship between input features and a binary target variable by fitting a sigmoid curve to the data. It allows me to estimate the probability of a sample belonging to a positive class.\n",
    "- **Fitting and evaluating the model**: I will demonstrate how to fit a logistic regression model to training data, assess its coefficients, and use the trained model to predict class labels for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace54900-f5d5-4748-99e0-f60317b1c9e2",
   "metadata": {},
   "source": [
    "## Code Breakdown and Explanation\n",
    "\n",
    "### 1. Importing Libraries and the Dataset\n",
    "I start by importing the necessary libraries for data manipulation and logistic regression. I then load the dataset, which contains information on students' exam performance based on study hours and practice test scores. I display the first few rows of the dataset to get an overview of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6048bc36-0c9d-477e-bf7f-ef24f5cbf95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hours_studied  practice_test  passed_exam\n",
      "0              0             55            0\n",
      "1              1             75            0\n",
      "2              2             32            0\n",
      "3              3             80            0\n",
      "4              4             75            0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "codecademyU = pd.read_csv('data.csv')\n",
    "print(codecademyU.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b1cb4-2b29-4d11-87d9-d5d098f76cdb",
   "metadata": {},
   "source": [
    "## 2. Preparing Data for the Model\n",
    "Next, I separate the dataset into input features (X) and the target variable (y). The features include the number of hours studied and the score on practice tests, while the target variable indicates whether the student passed the exam (1) or not (0).\n",
    "\n",
    "Before fitting the model, I standardise the features using StandardScaler to ensure that they are on a similar scale. This is important because logistic regression is sensitive to the scale of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d959489d-5816-451e-adba-3069b5c18fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out X and y\n",
    "X = codecademyU[['hours_studied', 'practice_test']]\n",
    "y = codecademyU.passed_exam\n",
    "\n",
    "# Transform X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e1e0a-a48c-4b98-9d26-9d59fbb85fe6",
   "metadata": {},
   "source": [
    "## 3. Splitting the Dataset into Training and Testing Sets\n",
    "I split the dataset into training and testing sets using an 80-20 split. This helps in evaluating the model’s performance on unseen data after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8867ad56-ba5c-4743-981e-515b1f9db4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593be5e-83fe-42c4-9aa3-055c4db4bf2f",
   "metadata": {},
   "source": [
    "## 4. Fitting the Logistic Regression Model\n",
    "Here, I create an instance of the logistic regression model and fit it to the training data. After fitting, I print the model’s coefficients and intercept to gain insight into the relationship between the input features and the target variable. The coefficients indicate how much each feature contributes to the probability of passing the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66a43014-b979-4b69-a814-b60aa03672aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.51032451 0.11984701]]\n",
      "[-0.13193653]\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cc_lr = LogisticRegression()\n",
    "cc_lr.fit(X_train, y_train)\n",
    "# Print the intercept and coefficients\n",
    "print(cc_lr.coef_)\n",
    "print(cc_lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d492d-ae69-466a-a555-f8c1e861e7f3",
   "metadata": {},
   "source": [
    "## 5. Making Predictions with the Trained Model\n",
    "After training the model, I can use it to make predictions on new data points. In sklearn, the .predict() method takes a matrix of features as input and returns a vector of predicted class labels (0 or 1). The model predicts whether each sample belongs to the positive class based on a probability threshold (default is 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f514dbe0-358f-44e3-81cb-553e8c865829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1]\n",
      "\n",
      "[[-0.43355498  0.29722219]\n",
      " [ 0.95382097  0.29722219]\n",
      " [-1.64750894 -1.79313169]\n",
      " [ 0.26013299  0.42786931]\n",
      " [ 1.30066495  0.62383999]]\n",
      "\n",
      "[[0.67942358 0.32057642]\n",
      " [0.20680975 0.79319025]\n",
      " [0.94454394 0.05545606]\n",
      " [0.42257111 0.57742889]\n",
      " [0.12928955 0.87071045]]\n",
      "\n",
      "7     0\n",
      "15    1\n",
      "0     0\n",
      "11    0\n",
      "17    1\n",
      "Name: passed_exam, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print out the predicted outcomes for the test data\n",
    "print(cc_lr.predict(X_test))\n",
    "print()\n",
    "print(X_test)\n",
    "print()\n",
    "# Print out the predicted probabilities for the test data\n",
    "print(cc_lr.predict_proba(X_test))\n",
    "print()\n",
    "# Print out the true outcomes for the test data\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7fecf-0365-4506-b2be-7907367c62c4",
   "metadata": {},
   "source": [
    "### Understanding prediction results\n",
    "\n",
    "With predict_proba(), the return values relate to the probability of the prediction being 0 ('fail) or 1 ('pass'). In the case of sample 1 here, [0.67934073 0.32065927], there is a 68% probability of a fail, 32% probability of a pass (adding up to 100%).\n",
    "\n",
    "You should see that the fourth datapoint was incorrectly classified as having passed the exam; however, the predicted probability of passing for this datapoint was only 57.7%, which is much lower than the other students who were correctly predicted to pass the exam (79.3% and 87.1%, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6403abe-efc0-4696-99f1-ed9cbed477bb",
   "metadata": {},
   "source": [
    "## 6. Evaluating the Model with Accuracy, Precision, Recall, F1-score, and Confusion Matrix\n",
    "To assess the model's performance, I import the necessary metrics from sklearn.metrics. I then calculate and print:\n",
    "\n",
    "- Accuracy: Measures the proportion of correctly classified samples.\n",
    "- Precision: The proportion of positive identifications that were actually correct.\n",
    "- Recall: The proportion of actual positives that were correctly identified.\n",
    "- F1-score: A harmonic mean of precision and recall.\n",
    "- Confusion matrix: Provides a summary of correct and incorrect predictions with respect to the true class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79b9823a-142d-49a8-9cc7-91159b971c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1 Score: 0.80\n",
      "Confusion Matrix:\n",
      "[[2 1]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef47fd8-28ac-461b-bfb6-644520df5389",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this extended project, I successfully demonstrated how to:\n",
    "\n",
    "- Fit a logistic regression model using the sklearn library.\n",
    "- Standardise the features to improve the model's performance.\n",
    "- Interpret the model's coefficients to understand feature importance.\n",
    "- Predict the probability of passing an exam based on input features such as hours studied and practice test scores.\n",
    "- Evaluate the model using accuracy, precision, recall, F1-score, and a confusion matrix to understand its effectiveness.\n",
    "\n",
    "This project provided a comprehensive introduction to implementing logistic regression in Python using sklearn and explored how to interpret and evaluate the results from a fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8bbe1c-20fc-4202-9921-91fcd52ebeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
